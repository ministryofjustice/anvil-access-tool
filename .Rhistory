tags$meta("http-equiv" = "X-UA-compatible", content = "IE = edge")
includeScript("www/IE.js")
## Load prison dropdown from s3
# dt.prisons <- data.table::as.data.table(s3tools::s3_path_to_full_df(
#   "alpha-app-anvil-access-tool/prisons_and_offices_v2.csv", header = FALSE))
dt.prisons <- data.table::as.data.table(s3tools::s3_path_to_full_df(
"alpha-app-anvil-access-tool/prison_area_lookup_aat.csv", header = FALSE))
View(dt.prisons)
fields <- c("first_name", "surname", "area", "prison", "role",
"id", "email", "date_requested",
"bentham", "bentham_status",
"drug_convey", "drug_convey_status",
"network", "network_status",
"visitors", "visitors_status",
"novel_drugs", "novel_drugs_status",
"reason")
email_choice <- c("@noms.gsi.gov.uk", "@justice.gov.uk", "@hmps.gov.uk", "@hmcts.gov.uk",
"@probation.gov.uk", "@justice.gsi.gov.uk", "@digital.justice.gov.uk")
foundErrors <- 0
quantumErr <- 0
tick <- "<i class=\"fa fa-check de-color\" aria-hidden=\"true\"></i>"
cross <- "<i class=\"fa fa-times de-color\" aria-hidden=\"true\"></i>"
## Reload data from S3
responses <- as.data.table(s3tools::s3_path_to_full_df(
"alpha-app-anvil-access-tool/anvil_app_responses_v6.csv",
header = TRUE))
View(responses)
names(responses) <- fields
View(responses)
responses[date_requested == "", date_requested := NA]
responses[bentham == "", bentham := 0]
responses[drug_convey == "", drug_convey := 0]
responses[network == "", network := 0]
responses[visitors == "", visitors := 0]
responses[novel_drugs == "", novel_drugs := 0]
responses[reason == "" | is.null(reason) | reason == "NULL", reason := NA]
responses$date_requested <- as.Date(responses$date_requested, origin = "1970-01-01")
View(responses)
responses <- as.data.table(s3tools::s3_path_to_full_df(
"alpha-app-anvil-access-tool/anvil_app_responses_v6.csv",
header = TRUE))
names(responses) <- fields
responses[date_requested == "", date_requested := NA]
responses[bentham == "", bentham := 0]
responses[drug_convey == "", drug_convey := 0]
responses[network == "", network := 0]
responses[visitors == "", visitors := 0]
responses[novel_drugs == "", novel_drugs := 0]
responses[reason == "" | is.null(reason) | reason == "NULL", reason := NA]
View(responses)
as.Date(responses$date_requested, format = "%Y-%m-%d")
as.Date(responses$date_requested)
format(as.Date(responses$date_requested), "%Y-%m-%d")
class(responses$date_requested)
str(responses)
responses[, date_requested := format(date_requested, "%Y-%m-%d")]
View(responses)
responses[, date_requested := format(as.Date(date_requested, format = "%d/%m/%Y"), "%Y-%m-%d")]
View(responses)
exists ("responses")
data$bentham <- as.integer(data$bentham)
data$drug_convey <- as.integer(data$drug_convey)
data$network <- as.integer(data$network)
runApp()
format(Sys.Date(), "%Y-%m-%d")
runApp()
runApp()
as.integer(TRUE)
as.integer(FALSE)
runApp()
runApp()
tick <- "<i class=\"fa fa-check de-color\" aria-hidden=\"true\"></i>"
cross <- "<i class=\"fa fa-times de-color\" aria-hidden=\"true\"></i>"
pending <- "<i class=\"far fa-clock de-color\" aria-hidden=\"true\"></i>"
status_lookup <- data.table(status=c("requested","approved","denied","created","deleted"),
status_disp=c(pending,
"Approved",
cross,
tick,
"Deleted"))
runApp()
runApp()
responses <- loadData()
responses <- loadData()
responses <- responses[(bentham == 1 | drug_convey == 1 | network == 1 | visitors == 1 | novel_drugs == 1),
c("first_name", "surname", "area", "prison", "role",
"id", "email", "date_requested",
"bentham", "bentham_status",
"drug_convey", "drug_convey_status",
"network", "network_status",
"visitors", "visitors_status",
"novel_drugs", "novel_drugs_status",
"reason")]
dt.prisons[active == T, soct_region]
"North West & West Midlands"
responses <- responses[area == "North West & West Midlands"]
##implement symbols
responses <- merge(responses, status_lookup[, .(status, bentham_status_disp=status_disp)],
by.x = "bentham_status", by.y = "status", all.x = T)
View(responses)
responses <- merge(responses, status_lookup[, .(status, network_status_disp=status_disp)],
by.x = "network_status", by.y = "status", all.x = T)
View(responses)
responses <- merge(responses, status_lookup[, .(status, drug_convey_status_disp=status_disp)],
by.x = "drug_convey_status", by.y = "status", all.x = T)
responses <- merge(responses, status_lookup[, .(status, visitors_status_disp=status_disp)],
by.x = "visitors_status", by.y = "status", all.x = T)
responses <- merge(responses, status_lookup[, .(status, novel_drugs_status_disp=status_disp)],
by.x = "novel_drugs_status", by.y = "status", all.x = T)
View(responses)
##only keep those to be displayed
responses[, name := paste0(first_name, " ", surname)]
responses <- responses[, .(name, role, id,
bentham_status_disp,
drug_convey_status_disp,
network_status_disp,
visitors_status_disp,
novel_drugs_status_disp)]
View(responses)
status_lookup <- data.table(status=c("requested","approved","denied","created","deleted",NA),
status_disp=c(pending,
"Approved",
cross,
tick,
"Deleted",
"N/A"))
##implement symbols
responses <- merge(responses, status_lookup[, .(status, bentham_status_disp=status_disp)],
by.x = "bentham_status", by.y = "status", all.x = T)
merge(data.table(a=c(NA, "a", "b")), data.table(a=c(NA, "b"),b=c("merged_na", "bbb")),by.x="a",by.y="b",all.x=T)
merge(data.table(a=c(NA, "a", "b")), data.table(a=c(NA, "b"),b=c("merged_na", "bbb")),by.x="a",by.y="a",all.x=T)
responses <- loadData()[(bentham == 1 | drug_convey == 1 | network == 1 | visitors == 1 | novel_drugs == 1)]
responses <- responses[area == "North West & West Midlands"]
##implement symbols
responses <- merge(responses, status_lookup[, .(status, bentham_status_disp=status_disp)],
by.x = "bentham_status", by.y = "status", all.x = T)
View(responses)
responses <- merge(responses, status_lookup[, .(status, network_status_disp=status_disp)],
by.x = "network_status", by.y = "status", all.x = T)
responses <- merge(responses, status_lookup[, .(status, drug_convey_status_disp=status_disp)],
by.x = "drug_convey_status", by.y = "status", all.x = T)
responses <- merge(responses, status_lookup[, .(status, visitors_status_disp=status_disp)],
by.x = "visitors_status", by.y = "status", all.x = T)
responses <- merge(responses, status_lookup[, .(status, novel_drugs_status_disp=status_disp)],
by.x = "novel_drugs_status", by.y = "status", all.x = T)
##only keep those to be displayed
responses[, name := paste0(first_name, " ", surname)]
responses <- responses[, .(name, role, id,
bentham_status_disp,
drug_convey_status_disp,
network_status_disp,
visitors_status_disp,
novel_drugs_status_disp)]
View(responses)
datatable(responses,
escape = FALSE,
options = list(paging = FALSE,
scrollCollapse = T,
dom = "ft",
scrollX = FALSE,
scrollY = "500px"),
rownames = FALSE,
colnames = c("Name", "Role", "Quantum ID",
"Seized Media", "Drug Conveyancing", "Network",
"Visitors", "Novel Drugs")
)
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
responses <- loadData()
View(responses)
colnames(responses)
responses[id == "AQA99A"]
responses[id == "AQA99A", bentham_status]
runApp()
runApp()
runApp()
runApp()
responses[id == tolower(input$quantum_id), bentham_status]
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
Sys.time()
format(Sys.time(), tz="Europe/London", "%Y-%m-%d")
format(Sys.time(), tz="Europe/London", "%Y-%m-%d %h:%m:%s")
format(Sys.time(), tz="Europe/London", "%Y-%m-%d %h:%m")
?format
format(Sys.time(), tz="Europe/London", "%Y-%m-%d %hh:%mm")
format(Sys.time(), tz="Europe/London", "%Y-%m-%d %H:%M")
format(Sys.time(), tz="Europe/London", "%Y-%m-%d %H:%M:%S")
format(Sys.time(), tz="Europe/London", "%Y-%m-%d %H:%M:%S")
responses <- loadData()[(bentham == 1 | drug_convey == 1 | network == 1 | visitors == 1 | novel_drugs == 1)]
responses
View(responses)
responses <- loadData()
## Reload data from S3
responses <- as.data.table(s3tools::s3_path_to_full_df(
"alpha-app-anvil-access-tool/anvil_app_responses_v6.csv",
header = TRUE))
##clean up fields and correct formats
names(responses) <- fields
View(responses)
responses[,.SD[which.max(date_requested)],by=id]
return(data[,.SD[which.max(date_requested)],by=id])
set.seed(42)
dat <- data.frame(A=c('a','a','a','b','b'),B=c(1,2,3,5,200),C=rnorm(5))
library(data.table)
dat <- as.data.table(dat)
dat[,.SD[which.max(B)],by=A]
dat[,.SD[which(max(B))],by=A]
dat[,.SD[which(B==max(B))],by=A]
set.seed(42)
dat <- data.frame(A=c('a','a','a','b','b'),B=c(1,NA,3,5,200),C=rnorm(5))
library(data.table)
dat <- as.data.table(dat)
dat[,.SD[which(B==max(B))],by=A]
dat[,.SD[which(B==max(na.omit(B)))],by=A]
set.seed(42)
dat <- data.frame(A=c('a','a','a','b','b','c','d'),B=c(1,NA,3,5,200,NA,1),C=rnorm(5))
library(data.table)
dat <- as.data.table(dat)
set.seed(42)
dat <- data.frame(A=c('a','a','a','b','b','c','d'),B=c(1,NA,3,5,200,NA,1),C=rnorm(7))
library(data.table)
dat <- as.data.table(dat)
dat
dat[,.SD[which(B==max(na.omit(B)))],by=A]
na.omit(c(NA))
max(na.omit(c(NA)))
length(na.omit(c(NA)))
dat[,.SD[which(ifelse(length(na.omit(B))==0,T,B==max(na.omit(B))))],by=A]
dat[,.SD[],by=A]
dat
na.omit(c(1,NA,3))
length(na.omit(c(1,NA,3)))
ifelse(length(na.omit(c(1,NA,3)))==0,T,c(1,NA,3))
ifelse(is.na(),"0000-00-00",)
test <- c(1,NA,3)
ifelse(is.na(test),"0000-00-00")
ifelse(is.na(test),"0000-00-00",test)
dat[,.SD[which.max(ifelse(is.na(B),0,B))],by=A]
## Reload data from S3
responses <- as.data.table(s3tools::s3_path_to_full_df(
"alpha-app-anvil-access-tool/anvil_app_responses_v6.csv",
header = TRUE))
names(responses) <- fields
responses[date_requested == "", date_requested := NA]
responses[bentham == "", bentham := 0]
responses[drug_convey == "", drug_convey := 0]
responses[network == "", network := 0]
responses[visitors == "", visitors := 0]
responses[novel_drugs == "", novel_drugs := 0]
responses[reason == "" | is.null(reason) | reason == "NULL", reason := NA]
responses[, date_requested := format(as.Date(date_requested, format = "%d/%m/%Y"), "%Y-%m-%d")]
View(responses)
set.seed(42)
dat <- data.frame(A=c('a','a','a','b','b','c','d'),B=format(as.Date(c("19/12/2017","19/12/2018","19/12/2019","19/12/2020",NA,NA,"19/12/2020"), format = "%d/%m/%Y"), "%Y-%m-%d"),C=rnorm(7))
library(data.table)
dat <- as.data.table(dat)
dat
dat[,.SD[which.max(ifelse(is.na(B),0,B))],by=A]
## Reload data from S3
responses <- as.data.table(s3tools::s3_path_to_full_df(
"alpha-app-anvil-access-tool/anvil_app_responses_v6.csv",
header = TRUE))
View(responses)
str(responses)
##clean up fields and correct formats
names(responses) <- fields
##clean up fields and correct formats
# names(responses) <- fields
responses[date_requested == "", date_requested := NA]
responses[bentham == "", bentham := 0]
responses[drug_convey == "", drug_convey := 0]
responses[network == "", network := 0]
responses[visitors == "", visitors := 0]
responses[novel_drugs == "", novel_drugs := 0]
responses[reason == "" | is.null(reason) | reason == "NULL", reason := NA]
View(responses)
responses[, date_requested := format(as.Date(date_requested, format = "%d/%m/%Y"), "%Y-%m-%d")]
View(responses)
set.seed(42)
dat <- data.frame(A=c('a','a','a','b','b','c','d'),B=format(as.Date(c("19/12/2017","19/12/2018","19/12/2018","19/12/2020",NA,NA,"19/12/2020"), format = "%d/%m/%Y"), "%Y-%m-%d"),C=rnorm(7))
library(data.table)
dat <- as.data.table(dat)
dat[,.SD[which.max(ifelse(is.na(B),0,B))],by=A]
dat
?which.max
dat[seq(dim(dat)[1],1)]
dim(dat)
seq(dim(dat))
seq(dim(dat))[1]
seq(dim(dat)[1],1)
seq(nrow(dat),1)
dat[seq(nrow(dat),1)]
View(responses)
View(responses)
##make sure there are no duplicate rows (for each quantum id).
##note order of the table is reversed and then restored...
##...to keep the latest entry if date_requested occurs more than once for a given quantum id.
responses <- responses[seq(nrow(responses),1)]
View(responses)
responses[, .SD[which.max(ifelse(is.na(date_requested),0,date_requested))], by=id]
warnings()
View(responses[, .SD[which.max(ifelse(is.na(date_requested),0,date_requested))], by=id])
View(responses[, .SD[which.max(ifelse(is.na(date_requested),0,date_requested))], by=id][, .(id,date_requested,email)])
View(responses)
View(responses[, .N, by=id])
## Reload data from S3
responses <- as.data.table(s3tools::s3_path_to_full_df(
"alpha-app-anvil-access-tool/anvil_app_responses_v6.csv",
header = TRUE))
View(responses)
View(responses[, .N, by = id])
View(responses[is.na(id)])
##clean up fields and correct formats
# names(responses) <- fields
responses[date_requested == "", date_requested := NA]
responses[bentham == "", bentham := 0]
max(c("2019-01-01", ""))
View(responses)
## Reload data from S3
responses <- as.data.table(s3tools::s3_path_to_full_df(
"alpha-app-anvil-access-tool/anvil_app_responses_v6.csv",
header = TRUE))
View(responses)
##clean up fields and correct formats
# names(responses) <- fields
responses[date_requested == "", date_requested := NA]
responses[bentham == "", bentham := 0]
responses[drug_convey == "", drug_convey := 0]
responses[network == "", network := 0]
responses[visitors == "", visitors := 0]
responses[novel_drugs == "", novel_drugs := 0]
responses[reason == "" | is.null(reason) | reason == "NULL", reason := NA]
View(responses)
##make sure there are no duplicate rows (for each quantum id).
##note order of the table is reversed and then restored...
##...to keep the latest entry if date_requested occurs more than once for a given quantum id.
responses <- responses[seq(nrow(responses),1)]
responses <- responses[, .SD[which.max(ifelse(is.na(date_requested),0,date_requested))], by=id]
warnings()
responses <- responses[, .SD[which.max(ifelse(is.na(date_requested),"",date_requested))], by=id]
responses <- as.data.table(s3tools::s3_path_to_full_df(
"alpha-app-anvil-access-tool/anvil_app_responses_v6.csv",
header = TRUE))
##clean up fields and correct formats
# names(responses) <- fields
responses[date_requested == "", date_requested := NA]
responses[bentham == "", bentham := 0]
responses[drug_convey == "", drug_convey := 0]
responses[network == "", network := 0]
responses[visitors == "", visitors := 0]
responses[novel_drugs == "", novel_drugs := 0]
responses[reason == "" | is.null(reason) | reason == "NULL", reason := NA]
##make sure there are no duplicate rows (for each quantum id).
##note order of the table is reversed and then restored...
##...to keep the latest entry if date_requested occurs more than once for a given quantum id.
responses <- responses[seq(nrow(responses),1)]
responses <- responses[, .SD[which.max(ifelse(is.na(date_requested),"",date_requested))], by=id]
warnings()
responses <- as.data.table(s3tools::s3_path_to_full_df(
"alpha-app-anvil-access-tool/anvil_app_responses_v6.csv",
header = TRUE))
##clean up fields and correct formats
# names(responses) <- fields
responses[date_requested == "", date_requested := NA]
responses[bentham == "", bentham := 0]
responses[drug_convey == "", drug_convey := 0]
responses[network == "", network := 0]
responses[visitors == "", visitors := 0]
responses[novel_drugs == "", novel_drugs := 0]
responses[reason == "" | is.null(reason) | reason == "NULL", reason := NA]
test <- responses[id == "mqc90u"]
test
responses[,.N,by=is.na(date_requested)]
ifelse(is.na(test$date_requested),"",test$date_requested)
which.max(ifelse(is.na(test$date_requested),"",test$date_requested))
which.max(ifelse(is.na(test$date_requested),"2020-01-01",test$date_requested))
which.max(ifelse(is.na(test$date_requested),as.Date("2020-01-01"),test$date_requested))
which.max(c("2020-01-01",""))
which.max(c(as.Date("2020-01-01"),""))
which.max(c(as.Date("2020-01-01"),as.Date("0000-00-00")))
which.max(c(as.Date("2020-01-01"),as.Date("0000-01-01")))
## Reload data from S3
responses <- as.data.table(s3tools::s3_path_to_full_df(
"alpha-app-anvil-access-tool/anvil_app_responses_v6.csv",
header = TRUE))
##clean up fields and correct formats
# names(responses) <- fields
responses[date_requested == "", date_requested := NA]
responses[bentham == "", bentham := 0]
responses[drug_convey == "", drug_convey := 0]
responses[network == "", network := 0]
responses[visitors == "", visitors := 0]
responses[novel_drugs == "", novel_drugs := 0]
responses[reason == "" | is.null(reason) | reason == "NULL", reason := NA]
##make sure there are no duplicate rows (for each quantum id).
##note order of the table is reversed and then restored...
##...to keep the latest entry if date_requested occurs more than once for a given quantum id.
responses <- responses[seq(nrow(responses),1)]
responses <- responses[,
.SD[which.max(ifelse(is.na(date_requested),
as.Date("0000-01-01"),
as.Date(date_requested)))],
by=id]
responses <- responses[seq(nrow(responses),1)]
View(responses)
test
test$date_requested <- "2020-05-12"
test
data <- test
responses <- rbind(responses, data, fill = F)
View(responses)
##make sure there are no duplicate rows (for each quantum id).
##note order of the table is reversed and then restored...
##...to keep the latest entry if date_requested occurs more than once for a given quantum id.
responses <- responses[seq(nrow(responses),1)]
View(responses)
responses <- responses[,
.SD[which.max(ifelse(is.na(date_requested),
as.Date("0000-01-01"),
as.Date(date_requested)))],
by=id]
View(responses)
responses <- responses[seq(nrow(responses),1)]
View(responses)
runApp()
runApp()
?s3_path_to_full_df
library(s3tools)
?invisible
unlist(responses[id == tolower("MQC90u"), bentham]) == 1)
unlist(responses[id == tolower("MQC90u"), bentham])
runApp()
unlist(responses[id == tolower("iqa97b"), bentham])
unlist(responses[id == tolower("iqa97b"), bentham])==1
runApp()
runApp()
runApp()
?substring
substring("mqc90u",2,2)
substring("mqc90u",2,1)
substring("mqc90u",1,1)
substring("mqc90u",2,2)
substring("mqc90u",4,5)
as.numeric(substring("mqc90u",4,5))
as.numeric(substring("mqc9au",4,5))
is.na(as.numeric(substring("mqc9au",4,5)))
is.na(grepl("[0-9]",substring("mqc9au",4,5)))
is.na(grepl("[0-9]",substring("mqc90u",4,5)))
is.na(grepl("[0-9]",substring("mqc90u",4,5)))
?grepl
is.na(grepl("[0-9]",substring("mqc90u",4,5), perl = T))
is.na(as.integer(substring("mqc9au",4,5)))
is.na(grepl("[[:digit:]]",substring("mqc90u",4,5), perl = T))
is.na(grepl("[[:digit:]]",substring("mqc90u",4,5)))
is.na(grepl("[0-9]{2}",substring("mqc90u",4,5), perl = T))
substring("mqc90u",4,5)
grepl("[0-9]{2}","90")
is.na(grepl("[0-9]{2}",substring("mqc90u",4,5)))
grepl("[0-9]{2}",substring("mqc90u",4,5))
grepl("[0-9]{2}",substring("mqc9au",4,5))
grepl("[0-9]{2}",substring("mqca0u",4,5))
grepl("[0-9]{2}",substring("mqcaau",4,5))
grepl("[0-9]{2}",substring("mqc88u",4,5))
grepl("[a-z]{1}q[a-z]{1}[0-9]{2}[a-z]{1}",tolower("MQC90u"))
grepl("[a-z]{1}q[a-z]{1}[0-9]{2}[a-z]{1}",tolower("MQC90"))
grepl("[a-z]{1}q[a-z]{1}[0-9]{2}[a-z]{1}",tolower("MQC90uu"))
grepl("^[a-z]{1}q[a-z]{1}[0-9]{2}[a-z]{1}$",tolower("MQC90uu"))
grepl("^[a-z]{1}q[a-z]{1}[0-9]{2}[a-z]{1}$",tolower("MQC90u0"))
grepl("^[a-z]{1}q[a-z]{1}[0-9]{2}[a-z]{1}$",tolower("MQC9au"))
grepl("^[a-z]{1}q[a-z]{1}[0-9]{2}[a-z]{1}$",tolower("MQC90u"))
grepl("^[a-z]{1}q[a-z]{1}[0-9]{2}[a-z]{1}$",tolower("MQCa0u"))
grepl("^[a-z]{1}q[a-z]{1}[0-9]{2}[a-z]{1}$",tolower("MQC90u"))
grepl("^[a-z]{1}q[a-z]{1}[0-9]{2}[a-z]{1}$",tolower("MaC90u"))
grepl("^[a-z]{1}q[a-z]{1}[0-9]{2}[a-z]{1}$",tolower("MqC90u"))
grepl("^[a-z]{1}q[a-z]{1}[0-9]{2}[a-z]{1}$",tolower("qqC90u"))
grepl("^[a-z]{1}q[a-z]{1}[0-9]{2}[a-z]{1}$",tolower("aaqC90u"))
grepl("^[a-z]{1}q[a-z]{1}[0-9]{2}[a-z]{1}$",tolower("aq90u"))
grepl("^[a-z]{1}q[a-z]{1}[0-9]{2}[a-z]{1}$",tolower("aqaa90u"))
grepl("^[a-z]{1}q[a-z]{1}[0-9]{2}[a-z]{1}$",tolower("aqa90u"))
runApp()
runApp()
runApp()
runApp()
